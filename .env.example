# ======================
# LLM Settings
# ======================
# Any OpenAI-compatible chat completions endpoint
# Works with: GOSI Brain, Ollama, vLLM, LiteLLM, any OpenAI-compatible API
CUSTOM_LLM_API_ENDPOINT=https://your-llm-platform.example.com/api/chat/completions
CUSTOM_LLM_API_KEY=your-api-key-here
CUSTOM_LLM_MODEL_NAME=your-model-name
# Security defaults: keep SSL verification ON in all non-local environments.
LLM_SSL_VERIFY=true
# Debug only. Logs sanitized curl command with redacted auth headers.
LOG_LLM_CURL=false

# ======================
# Backend Server
# ======================
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
# Optional: enable LangGraph in-memory checkpointer for replay/debug.
ENABLE_LANGGRAPH_CHECKPOINTER=false
