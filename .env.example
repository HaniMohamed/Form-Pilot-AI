# ======================
# LLM Provider Settings
# ======================
# Provider: "openai", "azure_openai", "watsonx", or "custom"
LLM_PROVIDER=openai

# OpenAI
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL_NAME=gpt-4o

# Azure OpenAI (if using azure_openai provider)
AZURE_OPENAI_API_KEY=your-azure-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# watsonx (if using watsonx provider)
WATSONX_API_KEY=your-watsonx-api-key-here
WATSONX_URL=https://us-south.ml.cloud.ibm.com
WATSONX_PROJECT_ID=your-project-id-here
WATSONX_MODEL_ID=ibm/granite-13b-chat-v2

# Custom OpenAI-compatible API (if using custom provider)
# Works with any endpoint that follows the OpenAI chat completions format
# Example: GOSI Brain (https://llm-platform.gosi.ins/api/chat/completions)
CUSTOM_LLM_API_ENDPOINT=https://your-llm-platform.example.com/api/chat/completions
CUSTOM_LLM_API_KEY=your-api-key-here
CUSTOM_LLM_MODEL_NAME=your-model-name

# ======================
# Backend Server
# ======================
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
